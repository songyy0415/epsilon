#! python3
import argparse, collections, pathlib, sys

parser = argparse.ArgumentParser(
    description='Compare CSV test results to measure improvement and detect regressions.\nThese CSVs may be generated by filtering the test output like this : test.bin | grep "^\\(CRASH\\|BAD\\|OK\\)" > results.csv'
)
parser.add_argument("before", metavar="before.csv", type=pathlib.Path)
parser.add_argument("after", metavar="after.csv", type=pathlib.Path)
parser.add_argument(
    "--markdown", action="store_true", help="format output with Markdown"
)

Line = collections.namedtuple("Line", ["result", "input", "expected", "actual"])


def parse_line(line):
    type, input, *remaining = line.split("\t")
    if len(remaining) > 0:
        expected = remaining[0]
    else:
        expected = "GOOD"
    if type == "CRASH":
        actual = "CRASH"
    elif type == "BAD":
        if len(remaining) > 1:
            actual = remaining[1]
        else:
            actual = "BAD"
    else:
        assert type == "OK"
        actual = expected
    return Line(type, input, expected, actual)


def main():
    args = parser.parse_args()

    if not args.before.exists() or not args.after.exists():
        print("File not found", file=sys.stderr)
        sys.exit(1)

    before = args.before.read_text().split("\n")
    after = args.after.read_text().split("\n")

    if len(before) != len(after):
        print(
            "The two CSVs must be created with the same test suite, please rebase the target branch",
            file=sys.stderr,
        )
        sys.exit(1)

    fixed, broken, changed = [], [], []
    totalOK, totalBAD, totalCRASH = 0, 0, 0
    for old, new in zip(before, after):
        if not old:
            continue
        old = parse_line(old)
        new = parse_line(new)
        assert old.input == new.input

        if new.result == "OK":
            totalOK += 1
        elif new.result == "BAD":
            totalBAD += 1
        elif new.result == "CRASH":
            totalCRASH += 1

        if new == old:
            continue

        if new.result == "OK":
            fixed.append(new.input)
            continue

        message = (
            f"{new.input}\n"
            + f"  before    {old.actual}\n"
            + f"  after     {new.actual}\n"
            + f"  expected  {new.expected}"
        )

        if old.result == "OK" or (old.result == "BAD" and new.result == "CRASH"):
            broken.append(message)
        else:
            changed.append(message)

    for items, name in (fixed, "fixed"), (changed, "changed"), (broken, "broken"):
        if not items:
            continue
        if args.markdown:
            print(f"<details><summary>{len(items)} {name}</summary><pre>")
        else:
            print("=" * 8, len(items), name, "=" * 8)
        for item in items:
            print(item)
        if args.markdown:
            print(f"</pre></details>")

    if args.markdown:
        print(f"<details><summary>Overall status</summary>")
        print("")
        print(f"```mermaid")
        print(
            "%%{init: { 'themeVariables': { 'pie1': '#50C102', 'pie2': '#FFB734', 'pie3': '#FF000c'}}}%%"
        )
        print(f"pie showdata")
        for total, name in (totalOK, "OK"), (totalBAD, "BAD"), (totalCRASH, "CRASH"):
            print('"', name, '" : ', total)
        print(f"```")
        print("")
        print(f"</details>")


if __name__ == "__main__":
    main()
